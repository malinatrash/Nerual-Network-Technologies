{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "cWRjD0Y-f8Z4"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random # библиотека функций для генерации случайных значений\n",
        "# Сторонние библиотеки\n",
        "import numpy as np # библиотека функций для работы с матрицами\n",
        "\"\"\" ---Раздел описаний--- \"\"\"\n",
        "\"\"\" --Описание класса Network--\"\"\"\n",
        "class Network(object): # используется для описания нейронной сети\n",
        "    def __init__(self, sizes): # конструктор класса\n",
        "# self – указатель на объект класса\n",
        "# sizes – список размеров слоев нейронной сети\n",
        "        self.num_layers = len(sizes) # задаем количество слоев нейронной сети\n",
        "        self.sizes = sizes # задаем список размеров слоев нейронной сети\n",
        "        self.biases = [np.random.randn(y, 1)*math.sqrt(2/y) for y in sizes[1:]] # задаем случайные начальные смещения\n",
        "        self.weights = [np.random.randn(y, x)*math.sqrt(2/y) for x, y in zip(sizes[:-1], sizes[1:])] # задаем случайные начальные веса связей\n",
        "    def sigmoid(self, z):\n",
        "      return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def feedforward(self, a):\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            a = self.sigmoid(np.dot(w, a)+b)\n",
        "        return a\n",
        "    def SGD( # Стохастический градиентный спуск\n",
        "        self # указатель на объект класса\n",
        "        , training_data # обучающая выборка\n",
        "        , epochs # количество эпох обучения\n",
        "        , mini_batch_size # размер подвыборки\n",
        "        , eta # скорость обучения\n",
        "        , test_data # тестирующая выборка\n",
        "        ):\n",
        "        test_data = list(test_data) # создаем список объектов тестирующей выборки\n",
        "        n_test = len(test_data) # вычисляем длину тестирующей выборки\n",
        "        training_data = list(training_data) # создаем список объектов обучающей выборки\n",
        "        n = len(training_data) # вычисляем размер обучающей выборки\n",
        "        for j in range(epochs): # цикл по эпохам\n",
        "            random.shuffle(training_data) # перемешиваем элементы обучающей выборки\n",
        "            mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, n, mini_batch_size)] # создаем подвыборки\n",
        "            for mini_batch in mini_batches: # цикл по подвыборкам\n",
        "              #print(len(mini_batch[0][0]))\n",
        "              self.update_mini_batch(mini_batch, eta) # один шаг градиентного спуска\n",
        "            print (\"Epoch {0}: {1} / {2}\".format(j, self.evaluate(test_data), n_test)) # смотрим прогресс в обучении\n",
        "    def update_mini_batch( # Шаг градиентного спуска\n",
        "        self # указатель на объект класса\n",
        "        , mini_batch # подвыборка\n",
        "        , eta # скорость обучения\n",
        "        ):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases] # список градиентов dC/db для каждого слоя (первоначально заполняются нулями)\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights] # список градиентов dC/dw для каждого слоя (первоначально заполняются нулями)\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y) # послойно вычисляем градиенты dC/db и dC/dw для текущего прецедента (x, y)\n",
        "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)] # суммируем градиенты dC/db для различных прецедентов текущей подвыборки\n",
        "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)] # суммируем градиенты dC/dw для различных прецедентов текущей подвыборки\n",
        "        self.weights = [w-(eta/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)] # обновляем все веса w нейронной сети\n",
        "        self.biases = [b-(eta/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)] # обновляем все смещения b нейронной сети\n",
        "    def backprop( # Алгоритм обратного распространения\n",
        "        self # указатель на объект класса  \n",
        "      ,x # вектор входных сигналов , \n",
        "      ,y # ожидаемый вектор выходных сигналов\n",
        "      ):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases] # список градиентов dC/db для каждого слоя (первоначально заполняются нулями)\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights] # список градиентов dC/dw для каждого слоя (первоначально заполняются нулями)\n",
        "        # определение переменных\n",
        "        activation = x # выходные сигналы слоя (первоначально соответствует выходным сигналам 1-го слоя или входным сигналам сети)\n",
        "        activations = [x] # список выходных сигналов по всем слоям (первоначально содержит только выходные сигналы 1-го слоя)\n",
        "        zs = [] # список активационных потенциалов по всем слоям (первоначально пуст)\n",
        "        # прямое распространение\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            z = np.dot(w, activation)+b # считаем активационные потенциалы текущего слоя\n",
        "            zs.append(z) # добавляем элемент (активационные потенциалы слоя) в конец списка\n",
        "            activation = self.sigmoid(z) # считаем выходные сигналы текущего слоя, применяя сигмоидальную функцию активации к активационным потенциалам слоя\n",
        "            activations.append(activation) # добавляем элемент (выходные сигналы слоя) в конец списка\n",
        "  # обратное распространение\n",
        "        delta = self.cost_derivative(activations[-1], y) * self.sigmoid_prime(zs[-1]) # считаем меру влияния нейронов выходного слоя L на величину ошибки (BP1)\n",
        "        nabla_b[-1] = delta # градиент dC/db для слоя L (BP3)\n",
        "        nabla_w[-1] = np.dot(delta, activations[-2].transpose()) # градиент dC/dw для слоя L (BP4)\n",
        "        for l in range(2, self.num_layers):\n",
        "          z = zs[-l] # активационные потенциалы l-го слоя (двигаемся по списку справа налево)\n",
        "          sp = self.sigmoid_prime(z) # считаем сигмоидальную функцию от активационных потенциалов l-го слоя\n",
        "          delta = np.dot(self.weights[-l+1].transpose(), delta) * sp # считаем меру влияния нейронов l-го слоя на величину ошибки (BP2)\n",
        "          nabla_b[-l] = delta # градиент dC/db для l-го слоя (BP3)\n",
        "          nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())# градиент dC/dw для l-го слоя (BP4)\n",
        "        return (nabla_b, nabla_w)\n",
        "    def evaluate(self, test_data):\n",
        "      test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
        "      correct_predictions = sum(int(x == y) for (x, y) in test_results)\n",
        "      total_tests = len(test_data)\n",
        "      accuracy = correct_predictions / total_tests\n",
        "      return accuracy\n",
        "    def cost_derivative(self, output_activations, y): # Вычисление частных производных стоимостной функции по выходным сигналам последнего слоя\n",
        "      return (output_activations-y)\n",
        "    def sigmoid_prime(self,z):# Производная сигмоидальной функции\n",
        "      return 1/np.cosh(z)**2\n",
        "    # def forward_propagate(self, row):\n",
        "    #     activation = row\n",
        "    #     for b, w in zip(self.biases, self.weights):\n",
        "    #         z = np.dot(w, activation)+b# zs.append(z)\n",
        "    #         activation = self.sigmoid(z)\n",
        "    #         activations.append(activation)\n",
        "\t  #     activation = activations\n",
        "    #     activations=[]\n",
        "\t  #   return activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sburJhFCORS2",
        "outputId": "35779cad-4ab8-4799-da4a-b9eff7958e09"
      },
      "outputs": [],
      "source": [
        "# ! wget https://github.com/GregVial/CoMNIST/blob/master/images/Cyrillic.zip\n",
        "# ! unzip Cyrilic.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jNB9_pOjzxI"
      },
      "source": [
        "Создайте нейронную сеть для распознавания рукописных цифр:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzx3xk25j1WK"
      },
      "source": [
        "Запустите процедуру обучения созданной нейронной сети, включающую 30 эпох:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4737 files belonging to 10 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-15 17:30:09.431940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [4737]\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2023-11-15 17:30:09.432189: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [4737]\n",
            "\t [[{{node Placeholder/_4}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[8], [8], [7], [3], [3], [6], [7], [6], [7], [9], [4], [10], [5], [3], [10], [1], [8], [7], [3], [9], [2], [10], [8], [5], [10], [7], [7], [4], [4], [8], [9], [8], [2], [10], [9], [2], [8], [10], [6], [8], [7], [6], [1], [5], [9], [7], [10], [3], [10], [5], [3], [8], [10], [9], [6], [9], [8], [4], [3], [4], [8], [9], [10], [4], [1], [6], [7], [4], [5], [7], [6], [2], [5], [10], [9], [1], [5], [9], [6], [2], [8], [6], [5], [9], [5], [5], [8], [9], [8], [4], [3], [8], [5], [9], [8], [9], [6], [8], [3], [6], [2], [6], [1], [3], [9], [6], [5], [6], [1], [9], [5], [6], [1], [9], [6], [10], [7], [9], [7], [7], [10], [8], [7], [1], [6], [5], [1], [10], [1], [7], [4], [9], [2], [8], [4], [8], [6], [9], [3], [2], [6], [5], [2], [7], [10], [1], [10], [2], [5], [1], [4], [9], [1], [8], [1], [6], [2], [4], [4], [9], [7], [7], [8], [2], [1], [7], [1], [6], [4], [1], [7], [3], [3], [4], [6], [8], [5], [8], [5], [10], [1], [1], [5], [2], [4], [6], [2], [6], [7], [4], [2], [4], [8], [1], [4], [8], [10], [5], [4], [9], [3], [9], [6], [3], [7], [9], [3], [4], [6], [8], [6], [2], [8], [1], [5], [1], [8], [10], [9], [10], [6], [2], [5], [6], [7], [8], [1], [7], [5], [2], [10], [7], [6], [5], [5], [7], [8], [3], [9], [3], [2], [7], [3], [9], [3], [3], [6], [2], [10], [6], [6], [5], [9], [3], [10], [10], [4], [4], [4], [6], [9], [6], [4], [1], [4], [10], [8], [2], [10], [3], [2], [3], [9], [3], [9], [5], [3], [4], [5], [6], [7], [6], [1], [3], [1], [10], [2], [3], [4], [9], [5], [10], [8], [5], [6], [6], [3], [9], [3], [9], [8], [4], [4], [2], [7], [6], [8], [5], [6], [9], [8], [2], [3], [9], [6], [4], [4], [9], [1], [10], [2], [1], [7], [7], [9], [2], [1], [1], [10], [9], [8], [8], [5], [3], [4], [4], [6], [10], [9], [8], [3], [2], [9], [10], [1], [4], [5], [10], [4], [1], [9], [8], [7], [6], [2], [1], [7], [5], [2], [7], [10], [2], [10], [5], [10], [1], [1], [3], [3], [1], [7], [10], [8], [10], [4], [6], [10], [3], [4], [3], [10], [7], [10], [2], [4], [3], [1], [7], [7], [7], [3], [1], [9], [4], [9], [1], [8], [3], [7], [5], [10], [7], [8], [5], [4], [8], [7], [1], [2], [9], [4], [4], [5], [9], [5], [5], [8], [5], [6], [4], [6], [4], [3], [8], [8], [5], [10], [10], [8], [9], [5], [1], [8], [2], [1], [10], [6], [1], [7], [4], [8], [1], [10], [8], [6], [3], [9], [10], [6], [10], [9], [9], [8], [2], [3], [4], [2], [6], [10], [10], [9], [4], [3], [5], [8], [8], [9], [9], [6], [10], [6], [2], [6], [10], [9], [6], [5], [4], [7], [6], [7], [10], [6], [2], [3], [1], [8], [4], [1], [3], [7], [8], [4], [4], [1], [1], [9], [3], [1], [2], [1], [4], [8], [2], [2], [8], [5], [2], [4], [3], [2], [10], [4], [4], [1], [6], [7], [8], [2], [9], [6], [3], [2], [3], [1], [8], [7], [9], [2], [1], [10], [9], [9], [1], [5], [5], [10], [7], [8], [3], [8], [4], [9], [7], [3], [6], [8], [10], [1], [1], [1], [6], [4], [9], [2], [1], [2], [6], [4], [1], [9], [8], [1], [10], [1], [9], [4], [6], [5], [2], [1], [9], [10], [5], [7], [6], [9], [7], [4], [9], [4], [6], [5], [1], [5], [2], [8], [4], [1], [4], [1], [7], [4], [5], [9], [5], [10], [8], [7], [6], [2], [9], [9], [1], [2], [6], [10], [10], [5], [6], [4], [3], [9], [7], [5], [8], [4], [8], [9], [9], [1], [9], [4], [3], [5], [10], [10], [7], [1], [4], [8], [5], [4], [3], [5], [5], [3], [5], [1], [4], [5], [1], [9], [8], [4], [5], [1], [1], [5], [2], [7], [6], [7], [10], [3], [9], [7], [8], [7], [3], [8], [10], [4], [3], [7], [2], [3], [9], [9], [6], [6], [8], [5], [2], [5], [5], [4], [7], [3], [2], [6], [8], [8], [4], [1], [8], [9], [10], [8], [2], [10], [5], [7], [2], [4], [10], [8], [1], [3], [6], [7], [2], [10], [2], [2], [4], [7], [3], [6], [10], [9], [7], [7], [7], [3], [7], [2], [1], [10], [2], [8], [8], [2], [4], [10], [5], [10], [8], [4], [9], [6], [7], [6], [1], [1], [8], [8], [10], [5], [9], [5], [7], [5], [9], [8], [5], [6], [2], [8], [9], [7], [10], [3], [10], [2], [1], [9], [6], [3], [10], [6], [3], [3], [6], [1], [8], [4], [6], [2], [2], [3], [9], [6], [4], [8], [4], [5], [7], [7], [6], [10], [2], [3], [4], [8], [6], [8], [8], [6], [5], [5], [9], [10], [5], [2], [10], [10], [3], [7], [5], [4], [2], [9], [9], [2], [10], [6], [9], [8], [4], [3], [8], [2], [6], [9], [1], [2], [8], [5], [5], [6], [4], [4], [7], [3], [8], [6], [1], [7], [5], [10], [4], [10], [8], [8], [9], [10], [5], [6], [9], [9], [9], [9], [7], [4], [10], [9], [1], [5], [6], [5], [10], [3], [4], [2], [8], [6], [5], [9], [5], [4], [5], [9], [9], [6], [9], [10], [5], [9], [9], [5], [4], [9], [4], [2], [6], [8], [5], [5], [1], [8], [6], [7], [8], [5], [4], [4], [8], [9], [10], [3], [3], [6], [10], [6], [4], [3], [2], [2], [1], [3], [7], [6], [6], [7], [10], [7], [10], [8], [10], [10], [10], [6], [5], [3], [9], [4], [1], [3], [8], [4], [4], [6], [2], [10], [7], [6], [10], [5], [9], [6], [1], [6], [2], [4], [7], [8], [5], [4], [10], [5], [10], [4], [5], [9], [8], [2], [5], [8], [6], [3], [8], [8], [7], [8], [8], [5], [6], [3], [3], [2], [10], [5], [8], [7], [5], [6], [5], [9], [4], [3], [10], [4], [3], [1], [4], [8], [5], [2], [10], [6], [8], [7], [6], [7], [6], [6], [4], [9], [8], [6], [5], [9], [10], [6], [5], [6], [2], [4], [3], [10], [1], [8], [9], [7], [4], [3], [10], [2], [4], [6], [3], [4], [4], [8], [8], [6], [9], [1], [2], [8], [1], [4], [2], [9], [9], [4], [10], [10], [7], [3], [2], [6], [3], [1], [1], [1], [1], [2], [6], [4], [5], [8], [8], [9], [5], [3], [2], [2], [8], [8], [4], [6], [2], [1], [4], [6], [4], [6], [6], [4], [9], [3], [3], [7], [2], [5], [6], [10], [8], [7], [1], [3], [8], [3], [1], [5], [2], [1], [7], [7], [6], [6], [2], [4], [7], [7], [5], [6], [5], [2], [7], [7], [7], [1], [8], [9], [4], [8], [9], [1], [8], [5], [6], [5], [8], [7], [7], [6], [1], [8], [3], [4], [7], [9], [1], [3], [3], [1], [5], [1], [1], [4], [7], [1], [10], [8], [9], [5], [4], [8], [10], [8], [7], [3], [1], [10], [6], [6], [5], [8], [3], [6], [4], [9], [10], [7], [10], [5], [10], [10], [7], [9], [9], [10], [8], [1], [9], [9], [9], [8], [7], [7], [5], [2], [9], [5], [10], [6], [8], [3], [3], [5], [7], [5], [7], [7], [8], [6], [3], [3], [6], [2], [1], [3], [10], [1], [5], [9], [10], [4], [3], [9], [8], [4], [8], [6], [2], [3], [3], [2], [6], [2], [3], [9], [3], [4], [5], [7], [3], [4], [4], [9], [2], [4], [5], [5], [8], [1], [8], [2], [1], [2], [7], [8], [8], [3], [5], [1], [2], [3], [10], [2], [9], [7], [6], [2], [5], [10], [1], [8], [5], [9], [8], [3], [3], [8], [3], [5], [9], [1], [3], [3], [8], [4], [8], [1], [8], [4], [3], [10], [10], [4], [9], [4], [6], [4], [2], [10], [4], [6], [1], [4], [1], [6], [8], [1], [1], [5], [3], [8], [8], [1], [5], [1], [8], [8], [7], [3], [9], [2], [7], [3], [8], [1], [1], [5], [3], [3], [2], [1], [4], [4], [7], [3], [6], [8], [9], [8], [8], [8], [1], [8], [9], [1], [10], [7], [4], [1], [1], [5], [4], [2], [9], [6], [10], [4], [7], [1], [4], [10], [5], [8], [9], [6], [6], [9], [9], [5], [10], [3], [5], [9], [4], [4], [8], [8], [1], [5], [2], [6], [8], [3], [8], [1], [8], [5], [10], [3], [4], [5], [3], [4], [9], [10], [10], [1], [1], [10], [10], [2], [9], [2], [7], [10], [4], [2], [8], [2], [9], [8], [7], [10], [7], [9], [2], [9], [7], [4], [2], [5], [1], [7], [10], [3], [7], [4], [3], [4], [5], [4], [6], [7], [10], [3], [5], [1], [10], [10], [2], [8], [6], [8], [2], [8], [3], [8], [4], [8], [4], [9], [7], [8], [9], [6], [3], [8], [8], [5], [7], [7], [8], [2], [5], [6], [5], [4], [8], [5], [6], [5], [10], [6], [3], [9], [2], [4], [1], [4], [3], [8], [8], [6], [4], [6], [2], [3], [7], [8], [3], [1], [7], [9], [8], [9], [6], [6], [8], [1], [3], [5], [1], [5], [6], [3], [6], [3], [7], [9], [1], [5], [3], [4], [9], [7], [8], [6], [4], [1], [9], [1], [5], [7], [9], [8], [2], [8], [4], [4], [7], [9], [5], [4], [1], [8], [2], [10], [8], [5], [2], [3], [5], [4], [2], [6], [2], [10], [8], [1], [3], [8], [9], [2], [6], [10], [9], [6], [7], [8], [8], [1], [3], [5], [6], [1], [5], [8], [3], [2], [2], [3], [6], [8], [5], [4], [5], [9], [8], [4], [4], [5], [7], [5], [7], [2], [9], [9], [3], [9], [8], [5], [8], [8], [7], [6], [8], [3], [3], [6], [8], [1], [9], [6], [10], [9], [3], [7], [7], [3], [6], [8], [5], [5], [4], [1], [4], [7], [1], [10], [9], [4], [7], [2], [8], [9], [5], [7], [6], [5], [4], [3], [10], [9], [8], [3], [1], [10], [9], [4], [2], [4], [4], [10], [10], [4], [3], [6], [10], [2], [1], [6], [5], [1], [1], [6], [2], [6], [1], [10], [10], [6], [10], [10], [1], [7], [6], [5], [1], [3], [2], [5], [4], [7], [2], [10], [7], [5], [5], [9], [10], [2], [3], [7], [8], [10], [5], [5], [2], [1], [2], [10], [7], [2], [2], [9], [6], [6], [6], [7], [8], [5], [5], [5], [8], [9], [3], [8], [4], [3], [1], [8], [7], [1], [2], [6], [6], [7], [6], [7], [5], [6], [6], [9], [8], [8], [1], [1], [3], [6], [10], [4], [5], [1], [2], [9], [10], [6], [10], [6], [6], [10], [2], [9], [7], [9], [8], [6], [10], [7], [9], [9], [9], [7], [4], [7], [4], [8], [9], [2], [3], [1], [5], [7], [1], [2], [4], [1], [4], [4], [3], [3], [7], [4], [8], [3], [1], [3], [2], [8], [1], [1], [5], [7], [2], [4], [9], [5], [5], [1], [4], [9], [3], [7], [9], [4], [6], [3], [3], [4], [6], [4], [3], [10], [5], [4], [3], [9], [9], [3], [10], [7], [7], [4], [4], [3], [9], [9], [9], [6], [7], [2], [9], [7], [10], [2], [5], [4], [7], [2], [6], [8], [6], [2], [7], [4], [3], [6], [5], [4], [9], [5], [8], [9], [10], [5], [4], [3], [4], [6], [6]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/q_/223hwj6s5yzgw6cmnmw4txbr0000gn/T/ipykernel_55689/1759447691.py:107: DeprecationWarning: Out of bound index found. This was previously ignored when the indexing result contained no elements. In the future the index error will be raised. This error occurs either due to an empty slice, or if an array has zero elements even before indexing.\n",
            "(Use `warnings.simplefilter('error')` to turn this DeprecationWarning into an error and get more details on the invalid index.)\n",
            "  e[j] = 1.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "image_size = (28, 28)\n",
        "dataset = tf.keras.utils.image_dataset_from_directory('Cyrillic',\n",
        "                                       seed=42,\n",
        "                                       color_mode=\"rgba\",\n",
        "                                       batch_size=1,\n",
        "                                       image_size=image_size)\n",
        "\n",
        "class_names = dataset.class_names\n",
        "\n",
        "###############################\n",
        "data = []\n",
        "Y = []\n",
        "for images, labels in dataset.take(4549):\n",
        "  for i in range(1):\n",
        "    img = Image.fromarray(images[i].numpy().astype(\"uint8\").squeeze())\n",
        "    img = img.convert(\"LA\")\n",
        "    #img = images[i].numpy().astype(\"uint8\").squeeze().convert(\"LA\")\n",
        "    imgData = np.asarray(img)\n",
        "    #print(imgData[0][0][0])\n",
        "\n",
        "    imgData_A=[]\n",
        "\n",
        "    for row in imgData:\n",
        "        imgData_A.extend(row[:,1])\n",
        "        \n",
        "    imgData_A=np.reshape(imgData_A,-1)\n",
        "\n",
        "    #Pixels higher than this will be 1. Otherwise 0.\n",
        "    THRESHOLD_VALUE=0\n",
        "    thresholdedData=0\n",
        "\n",
        "    thresholdedData = (imgData_A <= THRESHOLD_VALUE) * 1.0\n",
        "\n",
        "    unique, counts = np.unique(thresholdedData, return_counts=True)\n",
        "    result = np.column_stack((unique, counts)) \n",
        "\n",
        "    thresholdedData=np.reshape(thresholdedData,(28,28))\n",
        "    \n",
        "    data.append(thresholdedData)\n",
        "    Y.append([class_names[labels[i]]])\n",
        "\n",
        "#############################################\n",
        "for i in range(len(data)):\n",
        "  for j in range(len(data[i])):\n",
        "    for z in range(len(data[i][j])):\n",
        "      if (data[i][j][z] == 1):\n",
        "        data[i][j][z] = 0\n",
        "      else:\n",
        "        data[i][j][z] = 1\n",
        "############################################\n",
        "plt.figure(figsize=(8,8))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3,3,i+1)\n",
        "  plt.imshow(data[i])\n",
        "  plt.title(Y[i])\n",
        "  plt.axis('off')\n",
        "#############################################\n",
        "s = np.array(data.copy())\n",
        "vec_data = []\n",
        "for i in range(len(data)):\n",
        "  vec_data.append(s[i].reshape(-1,1))\n",
        "#############################################\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(vec_data, Y, test_size=0.4)\n",
        "\n",
        "#############################################\n",
        "X_train_new = []\n",
        "for i in range(len(X_train)):\n",
        "  Vec = []\n",
        "  for j in range(len(X_train[i])):\n",
        "    Vec.append(X_train[i][j][0])\n",
        "  X_train_new.append(Vec)\n",
        "\n",
        "X_test_new = []\n",
        "for i in range(len(X_test)):\n",
        "  Vec = []\n",
        "  for j in range(len(X_test[i])):\n",
        "    Vec.append(X_test[i][j][0])\n",
        "  X_test_new.append(Vec)\n",
        "\n",
        "X_train = X_train_new.copy()\n",
        "X_test = X_test_new.copy()\n",
        "###############################################\n",
        "class_mapping = {'Й': 0, 'К': 1, 'Л': 2, 'М': 3, 'Н': 4, 'О': 5, 'П': 6, 'Р': 7, 'С': 8, 'Т': 9}\n",
        "\n",
        "# Add the missing character\n",
        "class_mapping = {'Й': 0, 'К': 1, 'Л': 2, 'М': 3, 'Н': 4, 'О': 5, 'П': 6, 'Р': 7, 'С': 8, 'Т': 9}\n",
        "\n",
        "# Add the missing character\n",
        "class_mapping = {'Й': 0, 'К': 1, 'Л': 2, 'М': 3, 'Н': 4, 'О': 5, 'П': 6, 'Р': 7, 'С': 8, 'Т': 9, 'Й': 10}\n",
        "\n",
        "# Convert class labels to integers in y_train and y_test\n",
        "y_train = [[class_mapping.get(class_label, class_label) for class_label in sample] for sample in y_train]\n",
        "y_test = [[class_mapping.get(class_label, class_label) for class_label in sample] for sample in y_test]\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "############################\n",
        "\n",
        "print(y_test)\n",
        "def vectorized_result(j):\n",
        "    e = np.zeros((10, 1))\n",
        "    try:\n",
        "        e[j] = 1.0\n",
        "    except IndexError:\n",
        "        print(f\"Error: Index {j} is out of bounds for axis 0 with size 10.\")\n",
        "        print(\"Make sure your labels are in the expected range (0 to 9).\")\n",
        "    return e\n",
        "\n",
        "\n",
        "\n",
        "def load_data_wrapper(n):\n",
        "  training_inputs = [((np.reshape(x, (n,1)) > 0) * 1.0) for x in (X_train_new)]\n",
        "  training_results = [vectorized_result(y) for y in (y_train)]\n",
        "  training_data = list (zip(training_inputs, training_results))\n",
        "  test_inputs = [((np.reshape(x, (n,1)) > 0) * 1.0) for x in (X_test_new)]\n",
        "  test_data = list(zip(test_inputs,y_test))\n",
        "  return (training_data, test_data)\n",
        "\n",
        "training_data, test_data = load_data_wrapper(784)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/q_/223hwj6s5yzgw6cmnmw4txbr0000gn/T/ipykernel_55689/1759447691.py:107: DeprecationWarning: Out of bound index found. This was previously ignored when the indexing result contained no elements. In the future the index error will be raised. This error occurs either due to an empty slice, or if an array has zero elements even before indexing.\n",
            "(Use `warnings.simplefilter('error')` to turn this DeprecationWarning into an error and get more details on the invalid index.)\n",
            "  e[j] = 1.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "training_data,test_data = load_data_wrapper(784)\n",
        "lll8=np.reshape(training_data[444][0],(28,28))\n",
        "plt.imshow(lll8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Сеть net:\n",
            "Количетво слоев: 3\n",
            "Количество нейронов в слое 0 : 784\n",
            "Количество нейронов в слое 1 : 30\n",
            "Количество нейронов в слое 2 : 10\n",
            "W_ 1 :\n",
            "[[-0.89 -0.29  0.49 ...  0.02 -0.   -0.12]\n",
            " [-0.15 -0.28 -0.02 ...  0.2  -0.12 -0.03]\n",
            " [ 0.11  0.15 -0.01 ... -0.4  -0.16  0.1 ]\n",
            " ...\n",
            " [ 0.07 -0.25  0.26 ...  0.05 -0.17  0.43]\n",
            " [ 0.41 -0.23 -0.22 ... -0.13  0.01 -0.06]\n",
            " [-0.1   0.38  0.12 ...  0.04  0.44 -0.25]]\n",
            "b_ 1 :\n",
            "[[-0.39]\n",
            " [-0.08]\n",
            " [ 0.03]\n",
            " [-0.09]\n",
            " [ 0.25]\n",
            " [-0.04]\n",
            " [-0.09]\n",
            " [-0.05]\n",
            " [ 0.28]\n",
            " [ 0.19]\n",
            " [ 0.19]\n",
            " [-0.28]\n",
            " [ 0.21]\n",
            " [ 0.11]\n",
            " [-0.28]\n",
            " [ 0.16]\n",
            " [-0.02]\n",
            " [ 0.09]\n",
            " [ 0.15]\n",
            " [-0.01]\n",
            " [ 0.33]\n",
            " [ 0.59]\n",
            " [-0.29]\n",
            " [ 0.31]\n",
            " [ 0.25]\n",
            " [ 0.29]\n",
            " [-0.16]\n",
            " [-0.05]\n",
            " [ 0.06]\n",
            " [-0.31]]\n",
            "W_ 2 :\n",
            "[[-0.49  0.33 -1.01 -0.51 -0.56  0.16  0.58  0.23 -0.4   0.79 -0.87  0.37\n",
            "  -0.54 -0.27  0.64  0.22 -0.15 -0.22  0.2   0.11  0.11  0.14  0.87  0.13\n",
            "  -0.98  0.7  -0.37  0.19 -0.25 -0.19]\n",
            " [ 0.34 -0.57  0.65  0.49 -0.11  0.34  0.13 -0.4  -0.32 -0.02  0.54 -0.77\n",
            "   0.22 -0.    0.49 -0.26 -0.21 -0.17 -0.03 -0.07 -0.66  0.17  0.42  0.24\n",
            "   0.17  0.34 -0.83  0.31  0.35  0.59]\n",
            " [-0.14  0.05 -0.43 -0.82  0.25  0.32  0.22  0.16  0.28 -0.3  -0.87  0.2\n",
            "  -0.33  0.04 -0.25  0.45 -0.1   0.99 -0.1  -0.26 -0.18 -0.58 -0.34 -0.04\n",
            "  -0.39 -0.29 -0.09  0.97 -0.12 -0.02]\n",
            " [ 0.25  0.08  0.33  0.05  0.52 -0.1  -0.26 -0.1   0.49 -0.53 -0.69  0.06\n",
            "   0.78 -0.22  0.54 -0.7   0.13 -0.14  0.43  0.25 -0.01 -0.14  0.36  0.39\n",
            "   0.47  0.08  0.38  0.64 -0.1   0.23]\n",
            " [ 0.05 -0.47 -1.14 -0.35  0.17  0.5   0.1  -0.01  0.41  0.26 -0.35 -0.48\n",
            "  -0.03 -0.29  0.07 -0.34 -0.14  0.11  0.45  0.5  -0.55  0.2  -0.37 -0.32\n",
            "  -0.44 -0.1   0.75  0.43  0.15 -0.15]\n",
            " [ 0.1   0.53 -0.6   0.03  0.14 -0.44  0.96  0.1  -0.34 -0.26  0.11 -0.28\n",
            "   0.25 -0.07  0.22 -0.43  0.2  -0.01 -0.01  0.04 -0.42  0.12 -0.02 -0.64\n",
            "  -0.3  -0.21 -0.08  0.24  0.46  0.18]\n",
            " [-0.97 -0.63  0.05  1.31 -0.41  0.16  0.58 -0.75  0.04  0.21 -0.16  0.05\n",
            "  -0.06  0.65 -0.08  0.49 -0.5  -0.35  0.74 -0.34 -0.57  0.44 -0.23 -0.14\n",
            "  -0.73  0.11 -0.72  0.06  0.35 -0.18]\n",
            " [ 0.06  0.18  0.46  0.37 -0.52 -0.24 -0.31 -0.28 -0.16  0.14  0.32 -0.04\n",
            "   0.3   0.13 -0.42  0.56 -0.04 -0.13  0.48  0.72 -0.48  0.37  0.19  0.49\n",
            "  -0.17 -0.78  0.29 -0.12  1.26 -0.52]\n",
            " [-0.05 -0.07  0.11 -0.37 -0.51 -0.61 -0.29 -0.26  0.65  0.32  0.5   0.06\n",
            "  -0.12 -0.6  -0.35 -0.43  0.03  0.12  0.18 -0.2  -0.4  -0.15 -0.51  0.19\n",
            "   0.22 -0.52 -1.52  0.31 -0.33 -0.05]\n",
            " [-0.47 -0.31 -0.53  0.15 -0.15 -0.3   0.39  0.53  0.03  0.11  0.11  0.04\n",
            "  -0.09 -0.3   0.54  0.26  0.02  0.88  0.98 -0.21 -0.19 -0.54 -0.37 -1.39\n",
            "  -0.02 -0.59 -0.43  0.32 -0.62 -0.21]]\n",
            "b_ 2 :\n",
            "[[ 0.06]\n",
            " [ 0.49]\n",
            " [-0.44]\n",
            " [ 0.4 ]\n",
            " [ 0.07]\n",
            " [-0.47]\n",
            " [ 0.16]\n",
            " [-0.12]\n",
            " [ 0.46]\n",
            " [-1.21]]\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "net = Network([784, 30, 10])\n",
        "\"\"\" Вывод результата на экран: \"\"\" \n",
        "print('Сеть net:') \n",
        "print('Количетво слоев:', net.num_layers) \n",
        "for i in range(net.num_layers): \n",
        "    print('Количество нейронов в слое', i,':',net.sizes[i]) \n",
        "for i in range(net.num_layers-1): \n",
        "    print('W_',i+1,':') \n",
        "    print(np.round(net.weights[i],2)) \n",
        "    print('b_',i+1,':') \n",
        "    print(np.round(net.biases[i],2))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "shapes (10,0) and (1,30) not aligned: 0 (dim 1) != 1 (dim 0)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/Users/malinatrash/Library/Mobile Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns recognition/tsk.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m net\u001b[39m.\u001b[39mSGD(training_data, \u001b[39m30\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m0.05\u001b[39m, test_data\u001b[39m=\u001b[39mtest_data)\n",
            "\u001b[1;32m/Users/malinatrash/Library/Mobile Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns recognition/tsk.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m mini_batches \u001b[39m=\u001b[39m [training_data[k:k\u001b[39m+\u001b[39mmini_batch_size] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, n, mini_batch_size)] \u001b[39m# создаем подвыборки\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m mini_batch \u001b[39min\u001b[39;00m mini_batches: \u001b[39m# цикл по подвыборкам\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m   \u001b[39m#print(len(mini_batch[0][0]))\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_mini_batch(mini_batch, eta) \u001b[39m# один шаг градиентного спуска\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(j, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(test_data), n_test))\n",
            "\u001b[1;32m/Users/malinatrash/Library/Mobile Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns recognition/tsk.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m nabla_w \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mzeros(w\u001b[39m.\u001b[39mshape) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights] \u001b[39m# список градиентов dC/dw для каждого слоя (первоначально заполняются нулями)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m mini_batch:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     delta_nabla_b, delta_nabla_w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackprop(x, y) \u001b[39m# послойно вычисляем градиенты dC/db и dC/dw для текущего прецедента (x, y)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     nabla_b \u001b[39m=\u001b[39m [nb\u001b[39m+\u001b[39mdnb \u001b[39mfor\u001b[39;00m nb, dnb \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(nabla_b, delta_nabla_b)] \u001b[39m# суммируем градиенты dC/db для различных прецедентов текущей подвыборки\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     nabla_w \u001b[39m=\u001b[39m [nw\u001b[39m+\u001b[39mdnw \u001b[39mfor\u001b[39;00m nw, dnw \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(nabla_w, delta_nabla_w)] \u001b[39m# суммируем градиенты dC/dw для различных прецедентов текущей подвыборки\u001b[39;00m\n",
            "\u001b[1;32m/Users/malinatrash/Library/Mobile Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns recognition/tsk.ipynb Cell 8\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m delta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcost_derivative(activations[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], y) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmoid_prime(zs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m# считаем меру влияния нейронов выходного слоя L на величину ошибки (BP1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m nabla_b[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m delta \u001b[39m# градиент dC/db для слоя L (BP3)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m nabla_w[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(delta, activations[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mtranspose()) \u001b[39m# градиент dC/dw для слоя L (BP4)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malinatrash/Library/Mobile%20Documents/com~apple~CloudDocs/develop/Python/Nerual-Network-Technologies/patterns%20recognition/tsk.ipynb#X16sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m   z \u001b[39m=\u001b[39m zs[\u001b[39m-\u001b[39ml] \u001b[39m# активационные потенциалы l-го слоя (двигаемся по списку справа налево)\u001b[39;00m\n",
            "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (10,0) and (1,30) not aligned: 0 (dim 1) != 1 (dim 0)"
          ]
        }
      ],
      "source": [
        "net.SGD(training_data, 30, 10, 0.05, test_data=test_data)\n",
        "#  , training_data # обучающая выборка\n",
        "#         , epochs # количество эпох обучения\n",
        "#         , mini_batch_size # размер подвыборки\n",
        "#         , eta # скорость обучения\n",
        "#         , test_data # тестирующая выборка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 8  4  7 12 17 72  7 93 38  8  0]\n",
            " [ 4  7 16 26 26 48 24 58 25 32  0]\n",
            " [ 2  2 13 66 32 57  7 46 26 19  0]\n",
            " [ 2  5 11 48 41 57  7 60 43 20  0]\n",
            " [ 7  5 13 33 46 63 16 50 25 13  0]\n",
            " [ 7  2 11 44 29 59 11 50 23 15  0]\n",
            " [ 2  1  3 13 32 83 12 87 32 14  0]\n",
            " [20  5  6 26 20 73 20 70 33 20  0]\n",
            " [ 8  2  3  7 48 92 20 52 14 18  0]\n",
            " [ 6  7 23 33 30 39 12 61 47 17  0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Forward propagate input to a network output\n",
        "def forward_propagate(net, row):\n",
        "    inputs = row\n",
        "    for i in range(net.num_layers-1):\n",
        "        new_inputs = []\n",
        "        for b, w in zip(net.biases[i], net.weights[i]):\n",
        "            activation = np.dot(w,inputs)+b\n",
        "            out = net.sigmoid(activation)\n",
        "            new_inputs.append(out)\n",
        "        inputs = new_inputs\n",
        "    return new_inputs\n",
        "\t\t  \n",
        "\n",
        "\n",
        "# Make a prediction with a network\n",
        "def predict(net, row):\n",
        "    outputs = forward_propagate(net, row)\n",
        "    return outputs.index(max(outputs))\n",
        "\n",
        "i=-1\n",
        "X_train1=[]\n",
        "thresholdedData=[]\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    row=np.reshape(X_train[i], (1,784))\n",
        "    thresholdedData = (row > 0) * 1.0\n",
        "    X_train1.extend(thresholdedData)\n",
        "\n",
        "\n",
        "for i in range(len(X_train1)):\n",
        "    prediction = predict(net,X_train1[i])\n",
        "    if (i==0):\n",
        "      predictTrain = np.array([[prediction]])\n",
        "    else:\n",
        "      predictTrain =np.append(predictTrain,[[prediction]],axis=0)\n",
        "\n",
        "print(confusion_matrix(y_train, predictTrain))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MNIST_Федянина.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
